{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2048057_Program_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oD5AJ2U6f_q"
      },
      "source": [
        "---\n",
        "# <center> **NLP PROGRAM-4** </center>\n",
        "## <center> A program to get synonyms from WordNet </center>\n",
        "#### <center> Soundarya G_ 2048057</center>\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69Zd7BgG8qlK"
      },
      "source": [
        "## Downloading and Importing Wordnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oSc-C-r6TFt",
        "outputId": "b665c423-0c44-42a8-91f0-f360f105dbf1"
      },
      "source": [
        "# Downloading wordnet \n",
        "import nltk \n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "nltk.download('genesis')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXYFOyX-7tnm"
      },
      "source": [
        "# Importing required libraries \n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import wordnet_ic\n",
        "from nltk.corpus import genesis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRjKVvVJ82WX"
      },
      "source": [
        "# Wordnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xct2Glx1-nY6"
      },
      "source": [
        "A really useful lexical resource is WordNet. Its unique semantic network helps us find word relations, synonyms, grammars, etc. WordNet is just another NLTK corpus reader. The WordNet corpus reader gives access to the Open Multilingual WordNet, using ISO-639 language codes.\n",
        "\n",
        "> **Applications:** \n",
        "\n",
        "> This helps support NLP tasks such as sentiment analysis, automatic language translation, text similarity, and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cp9LXm4cn2r"
      },
      "source": [
        "## Word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6BjmaQEeJKX"
      },
      "source": [
        "> Discipline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh5_i8VO82l4",
        "outputId": "0b362bec-d008-4db6-b8ed-8e12d492eb5e"
      },
      "source": [
        "# Finding syset of the word ‘discipline’ \n",
        "\n",
        "syn = wordnet.synsets(\"discipline\") \n",
        "print(syn[0].name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discipline.n.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORDkxx4dd4bt",
        "outputId": "6892a7d5-99e0-4ddf-b258-9eaf31207390"
      },
      "source": [
        "type(syn[0].name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnQEZFv4eOi8"
      },
      "source": [
        "> Care"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4iAnU_5-9-L",
        "outputId": "e97c7ebe-3eb4-4a36-9f09-08114ed49fb7"
      },
      "source": [
        "syn = wordnet.synsets(\"care\") \n",
        "syn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('care.n.01'),\n",
              " Synset('caution.n.03'),\n",
              " Synset('concern.n.02'),\n",
              " Synset('care.n.04'),\n",
              " Synset('care.n.05'),\n",
              " Synset('care.n.06'),\n",
              " Synset('care.v.01'),\n",
              " Synset('care.v.02'),\n",
              " Synset('wish.v.02'),\n",
              " Synset('manage.v.02'),\n",
              " Synset('worry.v.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGFKKlTzeCX7",
        "outputId": "bf9dce79-d7f5-4300-e524-86e1d365855c"
      },
      "source": [
        "type(syn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FMa4330EWVy",
        "outputId": "84054501-37e0-4ecc-99a8-26d3cd163129"
      },
      "source": [
        "syn[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Synset('care.n.01')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8eJLocAF4Fz"
      },
      "source": [
        "## Lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df4sVXtGlpIr"
      },
      "source": [
        "Lemmas of code.v.02 (as in \"convert ordinary language into code\") are code.v.02.encipher, code.v.02.cipher, code.v.02.cypher, code.v.02.encrypt, code.v.02.inscribe, code.v.02.write_in_code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emnw6Ib9F3Qk",
        "outputId": "bc21d424-7818-43c0-9b2d-10dc1c921c02"
      },
      "source": [
        "print(syn[0].lemmas()[0].name()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "care\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zo5uMRpGP7J"
      },
      "source": [
        "## Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ze6sLgAGQJE",
        "outputId": "12cfc4a6-a2e9-4c90-ac00-ca970c45aef7"
      },
      "source": [
        "print(syn[0].definition()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the work of providing treatment for or attending to someone or something\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AHhNlU7GXYl",
        "outputId": "ebfd27e9-2053-4010-a2de-5c2fae4e2318"
      },
      "source": [
        "print(syn[3].definition()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a cause for feeling concern\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6gxL0k3Ggx1"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4tJKcKZGhA-",
        "outputId": "664b1f08-e9d6-4232-b3f2-f8422c9dc98d"
      },
      "source": [
        "print(syn[0].examples()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no medical care was required', 'the old car needs constant attention']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsghlv4jGz5E",
        "outputId": "cba15cd6-63b3-4b1e-cf35-6b87824191ae"
      },
      "source": [
        "print(syn[1].examples()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he exercised caution in opening the door', 'he handled the vase with care']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m9uFoWnGoU2",
        "outputId": "c1a8e544-89e8-4c5b-8ddf-08735e69f6c2"
      },
      "source": [
        "print(syn[3].examples()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['his major care was the illness of his wife']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaoNSLjChOhB"
      },
      "source": [
        "## Antonyms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQBuqxbEh5FB"
      },
      "source": [
        "> Synonyms of the word active are searched in the module synsets and are appended in the list synonyms. The same process is repeated for the Antonym also."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feMUVi8EhNeD",
        "outputId": "ce83afdf-fa90-48e8-abab-ff1db5918a6b"
      },
      "source": [
        "synonyms = [] \n",
        "antonyms = [] \n",
        "for syn_set in wordnet.synsets(\"light\"):  \n",
        "  for l in syn_set.lemmas(): \n",
        "    synonyms.append(l.name()) \n",
        "    if l.antonyms(): \n",
        "      antonyms.append(l.antonyms()[0].name()) \n",
        "print(\"\\nSet of synonyms of the word:\", set(synonyms))\n",
        "print(\"\\nSet of antonyms of the word:\", set(antonyms))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Set of synonyms of the word: {'unaccented', 'illumine', 'unhorse', 'scant', 'light-colored', 'spark', 'lightly', 'lighting', 'light', 'promiscuous', 'Inner_Light', 'Light', 'lighter', 'dismount', 'illumination', 'fire_up', 'easy', 'lite', 'lightness', 'lightheaded', 'brightness', 'illuminate', 'calorie-free', 'Light_Within', 'light-headed', 'visible_radiation', 'clear', 'light_source', 'luminance', 'ignite', 'lightsome', 'igniter', 'ignitor', 'alight', 'faint', 'abstemious', 'short', 'low-cal', 'sluttish', 'perch', 'visible_light', 'loose', 'sparkle', 'illume', 'light_up', 'unclouded', 'Christ_Within', 'swooning', 'luminosity', 'twinkle', 'weak', 'clean', 'tripping', 'idle', 'brightness_level', 'luminousness', 'wakeful', 'fall', 'get_off', 'get_down', 'wanton'}\n",
            "\n",
            "Set of antonyms of the word: {'heavy', 'extinguish', 'dark'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67_PgqquggWz",
        "outputId": "e511e80b-4278-455b-b363-4962c9aadb4c"
      },
      "source": [
        "synonyms = [] \n",
        "antonyms = [] \n",
        "for syn_set in wordnet.synsets(\"light\"):  \n",
        "  #for l in syn_set.lemmas(): \n",
        "  synonyms.append(syn_set.name()) \n",
        "    #if l.antonyms(): \n",
        "       #antonyms.append(l.antonyms()[0].name()) \n",
        "print(\"\\nSet of synonyms of the word:\", set(synonyms))\n",
        "print(\"\\nSet of antonyms of the word:\", set(antonyms))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Set of synonyms of the word: {'light.v.01', 'light.n.10', 'sparkle.n.01', 'light.s.11', 'light.n.08', 'light.s.18', 'light.s.23', 'light.s.19', 'light.a.13', 'light.n.09', 'light.s.20', 'light.n.12', 'light.a.06', 'light.s.09', 'light.n.03', 'light.n.06', 'luminosity.n.01', 'light.s.12', 'faint.s.04', 'light.s.16', 'easy.s.10', 'light.s.08', 'light.a.03', 'lighter.n.02', 'light.n.01', 'light_up.v.05', 'idle.s.04', 'light.n.14', 'clean.s.03', 'light.a.01', 'light.a.02', 'light.s.22', 'light.a.04', 'alight.v.01', 'light.a.14', 'light.n.07', 'unhorse.v.01', 'unaccented.s.02', 'lightly.r.02', 'abstemious.s.02', 'fall.v.20', 'light.n.05', 'inner_light.n.01', 'ignite.v.01', 'light.n.02', 'light.a.05', 'light.s.24'}\n",
            "\n",
            "Set of antonyms of the word: set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0BKl1UOHLNj"
      },
      "source": [
        "# Main Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69hVDlJoh9HO"
      },
      "source": [
        "> To find a word's synonym, part of speech, rank and definition.The words returned in range Minimum 10 Words-Maximum N Words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbfI_GItlt5K"
      },
      "source": [
        "def Program_4():\n",
        "  user_word = input(\"Enter the word: \")\n",
        "  syn = wordnet.synsets(user_word) \n",
        "\n",
        "  word_list =[]\n",
        "  pos_list = []\n",
        "  rank_list = []\n",
        "  defn_list = []\n",
        "\n",
        "  pos_dict = {'n':'noun','v':'verb','a':'adjective','r':'adverb','s':'singular'}\n",
        "\n",
        "  syn=list(syn)\n",
        "  list1=[]\n",
        "  for k in syn:\n",
        "    list1.append(k)\n",
        "    \n",
        "  for i in range(len(list1)):\n",
        "    value = str(list1[i])\n",
        "    chunks = re.split(\"['.]\",value)\n",
        "    word_list.append(chunks[1])\n",
        "    pos_list.append(pos_dict[chunks[2]])\n",
        "    rank_list.append(chunks[3])\n",
        "    defn_list.append(list1[i].definition())\n",
        "\n",
        "  df = pd.DataFrame(list(zip(word_list, pos_list,rank_list,defn_list)),\n",
        "                  columns =['Synonym Word', 'POS','Rank','Definition'])\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "ZFiYq2pkmGju",
        "outputId": "f37e4f68-09dc-4189-c583-f2915e3bf065"
      },
      "source": [
        "Program_4()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the word: care\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Synonym Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Rank</th>\n",
              "      <th>Definition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>care</td>\n",
              "      <td>noun</td>\n",
              "      <td>01</td>\n",
              "      <td>the work of providing treatment for or attendi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>caution</td>\n",
              "      <td>noun</td>\n",
              "      <td>03</td>\n",
              "      <td>judiciousness in avoiding harm or danger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>concern</td>\n",
              "      <td>noun</td>\n",
              "      <td>02</td>\n",
              "      <td>an anxious feeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>care</td>\n",
              "      <td>noun</td>\n",
              "      <td>04</td>\n",
              "      <td>a cause for feeling concern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>care</td>\n",
              "      <td>noun</td>\n",
              "      <td>05</td>\n",
              "      <td>attention and management implying responsibili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>care</td>\n",
              "      <td>noun</td>\n",
              "      <td>06</td>\n",
              "      <td>activity involved in maintaining something in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>care</td>\n",
              "      <td>verb</td>\n",
              "      <td>01</td>\n",
              "      <td>feel concern or interest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>care</td>\n",
              "      <td>verb</td>\n",
              "      <td>02</td>\n",
              "      <td>provide care for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>wish</td>\n",
              "      <td>verb</td>\n",
              "      <td>02</td>\n",
              "      <td>prefer or wish to do something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>manage</td>\n",
              "      <td>verb</td>\n",
              "      <td>02</td>\n",
              "      <td>be in charge of, act on, or dispose of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>worry</td>\n",
              "      <td>verb</td>\n",
              "      <td>02</td>\n",
              "      <td>be concerned with</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Synonym Word   POS Rank                                         Definition\n",
              "0          care  noun   01  the work of providing treatment for or attendi...\n",
              "1       caution  noun   03           judiciousness in avoiding harm or danger\n",
              "2       concern  noun   02                                 an anxious feeling\n",
              "3          care  noun   04                        a cause for feeling concern\n",
              "4          care  noun   05  attention and management implying responsibili...\n",
              "5          care  noun   06  activity involved in maintaining something in ...\n",
              "6          care  verb   01                           feel concern or interest\n",
              "7          care  verb   02                                   provide care for\n",
              "8          wish  verb   02                     prefer or wish to do something\n",
              "9        manage  verb   02             be in charge of, act on, or dispose of\n",
              "10        worry  verb   02                                  be concerned with"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6DAOWbwNDOU"
      },
      "source": [
        "# Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGr1qSatQj34"
      },
      "source": [
        "#### 1.Thesaurus-based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRUn_4JwNDeD"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "dog = wn.synset('dog.n.01')\n",
        "cat = wn.synset('cat.n.01')\n",
        "hit = wn.synset('hit.v.01')\n",
        "slap = wn.synset('slap.v.01')\n",
        "discovery = wn.synset('discovery.n.01')\n",
        "find = wn.synset('find.v.01')\n",
        "care_n = wn.synset('care.n.01')\n",
        "care_v = wn.synset('care.v.02')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEiGxLYYYpjd"
      },
      "source": [
        "- Path Similarity: \n",
        "> It is a similarity measure that finds the distance that is the length of the shortest path between two synsets. The score is in the range 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U98RnoI_YmdI",
        "outputId": "828041be-0961-4724-af68-e6f647866275"
      },
      "source": [
        "print(dog.path_similarity(cat))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1sot_EsYu2F",
        "outputId": "028495be-5baa-4595-8c24-f4b21dd93041"
      },
      "source": [
        "print(wn.path_similarity(hit, slap))   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14285714285714285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPScmOtLe8ok",
        "outputId": "7ff161b7-d7c3-4b8f-b89c-4e478a5ba13e"
      },
      "source": [
        "print(find.path_similarity(discovery))   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQsiPPzHf_5Q",
        "outputId": "3853f56f-c769-4d82-c9bb-59c324374b0d"
      },
      "source": [
        "print(find.path_similarity(find)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t4__MVRfsxX",
        "outputId": "b245148a-2ddf-43be-d8c0-02260b1a32d5"
      },
      "source": [
        "print(care_n.path_similarity(care_v)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0n29K0uklBz",
        "outputId": "d29abee3-9779-42dd-cc97-2da009007ec5"
      },
      "source": [
        "syn1 = wordnet.synsets('football')\n",
        "syn2 = wordnet.synsets('soccer')\n",
        "\n",
        "# A word may have multiple synsets, so need to compare each synset of word1 with synset of word2\n",
        "for s1 in syn1:\n",
        "    for s2 in syn2:\n",
        "        print(\"Path similarity of: \")\n",
        "        print(s1, '(', s1.pos(), ')', '[', s1.definition(), ']')\n",
        "        print(s2, '(', s2.pos(), ')', '[', s2.definition(), ']')\n",
        "        print(\"   is\", s1.path_similarity(s2))\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path similarity of: \n",
            "Synset('football.n.01') ( n ) [ any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other's goal ]\n",
            "Synset('soccer.n.01') ( n ) [ a football game in which two teams of 11 players try to kick or head a ball into the opponents' goal ]\n",
            "   is 0.5\n",
            "\n",
            "Path similarity of: \n",
            "Synset('football.n.02') ( n ) [ the inflated oblong ball used in playing American football ]\n",
            "Synset('soccer.n.01') ( n ) [ a football game in which two teams of 11 players try to kick or head a ball into the opponents' goal ]\n",
            "   is 0.05\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhyld6WOlPpU"
      },
      "source": [
        "Interpretation: The highest path similarity score of the words is 0.5, indicating they are closely related."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p91iGPMdY5sZ"
      },
      "source": [
        "- Leacock-Chodorow (LCH) Similarity: \n",
        "> It is a similarity measure which is an extended version of Path-based similarity as it incorporates the depth of the taxonomy. Therefore, it is the negative log of the shortest path (spath) between two concepts (synset_1 and synset_2) divided by twice the total depth of the taxonomy (D). The LCH similarity scores are between 0 and 3.689"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcFMIrSZY63g",
        "outputId": "52739aec-a53e-4d63-b75f-b684dfb2355a"
      },
      "source": [
        "print(dog.lch_similarity(cat))         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0281482472922856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1ifP1prZAK9",
        "outputId": "c89e6cf1-6c82-4354-a2a2-fdba78009df2"
      },
      "source": [
        "print(wn.lch_similarity(hit, slap)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3121863889661687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmUsPCtsZCja"
      },
      "source": [
        "- Wu-Palmer (WUP) Similarity: \n",
        "> Return a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node). The score can be 0 < score <= 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYgEkSj2ZCy3",
        "outputId": "45ef3c7a-5de6-4e22-d10b-588f7223a479"
      },
      "source": [
        "print(dog.wup_similarity(cat))          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJOXA4JNZgoX",
        "outputId": "bbca8a98-4913-40d9-9247-fa64632af5d0"
      },
      "source": [
        "print(wn.wup_similarity(hit, slap))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlTH5iyoQ0IF"
      },
      "source": [
        "#### 2. Information Content metrics( Thesaurus and Corpus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGSZWW1SZnak"
      },
      "source": [
        "- Resnik (RES) Similarity: \n",
        "> Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node). It ranges from 0 for terms without similarity to infinity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MMZi-MlZn15"
      },
      "source": [
        "# wordnet_ic Information Content: Load an information content file from the wordnet_ic corpus.\n",
        "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
        "# Or you can create an information content dictionary from a corpus \n",
        "genesis_ic = wn.ic(genesis, False, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FCLA8dlagqU",
        "outputId": "483e194a-01ae-401e-904d-406afe7f0837"
      },
      "source": [
        "print(dog.res_similarity(cat, brown_ic))         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.911666509036577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMdY4HrXabl3",
        "outputId": "e12e9424-d2ba-496c-929d-a89cb279b185"
      },
      "source": [
        "print(dog.res_similarity(cat, genesis_ic)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.204023991374837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-CXG9WPalCp"
      },
      "source": [
        "- Jiang-Conrath (JCN) Similarity: \n",
        "> Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node) and that of the two input Synsets.\n",
        "\n",
        "Equation: 1 / (IC(s1) + IC(s2) - 2 * IC(lcs))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc81NVmIbAuE",
        "outputId": "e2cc0f2b-7379-48f5-bd30-9990da5181fb"
      },
      "source": [
        "print(dog.jcn_similarity(cat, brown_ic)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4497755285516739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcDjFBFsbBrp",
        "outputId": "8931c6c5-9a94-458a-c2ec-b6b56f7c6ab2"
      },
      "source": [
        "print(dog.jcn_similarity(cat, genesis_ic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28539390848096946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqO_4T_nbBBv"
      },
      "source": [
        "- Lin Similarity: \n",
        "> Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node) and that of the two input Synsets.\n",
        "\n",
        "Equation: 2 * IC(lcs) / (IC(s1) + IC(s2))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSZ5oRCXbLpD",
        "outputId": "1604c597-8278-4479-ce47-491087afdf1c"
      },
      "source": [
        "print(dog.lin_similarity(cat, brown_ic))         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8768009843733973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9pU0WcjbLsV",
        "outputId": "bfeeb7c1-da67-4068-fa43-4600608f0f83"
      },
      "source": [
        "print(dog.lin_similarity(cat, genesis_ic)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8043806652422293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f08Y77hNbd1g"
      },
      "source": [
        "## Additional to Similarity\n",
        "\n",
        "If you also want the \"similar to\" list, that's not the same thing as the synonyms. For that, you call similar_tos() on each Synset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IPUDYanbeEP",
        "outputId": "959156da-18cc-4ff7-b98b-cf2155312521"
      },
      "source": [
        "for s in wn.synsets('small'):\n",
        "    print(s)\n",
        "    for sim in s.similar_tos():\n",
        "        print('  ->  {}'.format(sim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('small.n.01')\n",
            "Synset('small.n.02')\n",
            "Synset('small.a.01')\n",
            "  ->  Synset('atomic.s.03')\n",
            "  ->  Synset('bantam.s.01')\n",
            "  ->  Synset('bitty.s.01')\n",
            "  ->  Synset('dinky.s.01')\n",
            "  ->  Synset('dwarfish.s.01')\n",
            "  ->  Synset('elfin.s.02')\n",
            "  ->  Synset('gnomish.s.01')\n",
            "  ->  Synset('half-size.s.01')\n",
            "  ->  Synset('infinitesimal.s.01')\n",
            "  ->  Synset('lesser.s.02')\n",
            "  ->  Synset('micro.s.01')\n",
            "  ->  Synset('microscopic.s.04')\n",
            "  ->  Synset('miniature.s.01')\n",
            "  ->  Synset('minuscule.s.03')\n",
            "  ->  Synset('olive-sized.s.01')\n",
            "  ->  Synset('pocket-size.s.02')\n",
            "  ->  Synset('puny.s.02')\n",
            "  ->  Synset('slender.s.04')\n",
            "  ->  Synset('small-scale.s.01')\n",
            "  ->  Synset('smaller.s.01')\n",
            "  ->  Synset('smallish.s.01')\n",
            "  ->  Synset('subatomic.s.02')\n",
            "  ->  Synset('undersize.s.01')\n",
            "Synset('minor.s.10')\n",
            "  ->  Synset('limited.a.01')\n",
            "Synset('little.s.03')\n",
            "  ->  Synset('young.a.01')\n",
            "Synset('small.s.04')\n",
            "  ->  Synset('little.a.02')\n",
            "Synset('humble.s.01')\n",
            "  ->  Synset('inferior.a.01')\n",
            "Synset('little.s.07')\n",
            "  ->  Synset('lowercase.a.01')\n",
            "Synset('little.s.05')\n",
            "  ->  Synset('soft.a.03')\n",
            "Synset('small.s.08')\n",
            "  ->  Synset('fine.a.05')\n",
            "Synset('modest.s.02')\n",
            "  ->  Synset('moderate.a.01')\n",
            "Synset('belittled.s.01')\n",
            "  ->  Synset('decreased.a.01')\n",
            "Synset('small.r.01')\n"
          ]
        }
      ]
    }
  ]
}
