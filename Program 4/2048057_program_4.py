# -*- coding: utf-8 -*-
"""2048057_Program_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IgoiYOSD5pMT_SCmMijDMgMwq1TmlFBD

---
# <center> **NLP PROGRAM-4** </center>
## <center> A program to get synonyms from WordNet </center>
#### <center> Soundarya G_ 2048057</center>
---

## Downloading and Importing Wordnet
"""

# Downloading wordnet 
import nltk 
nltk.download('wordnet')
nltk.download('wordnet_ic')
nltk.download('genesis')

# Importing required libraries 
import re
import pandas as pd
from nltk.corpus import wordnet
from nltk.corpus import wordnet_ic
from nltk.corpus import genesis

"""# Wordnet

A really useful lexical resource is WordNet. Its unique semantic network helps us find word relations, synonyms, grammars, etc. WordNet is just another NLTK corpus reader. The WordNet corpus reader gives access to the Open Multilingual WordNet, using ISO-639 language codes.

> **Applications:** 

> This helps support NLP tasks such as sentiment analysis, automatic language translation, text similarity, and more.

## Word

> Discipline
"""

# Finding syset of the word ‘discipline’ 

syn = wordnet.synsets("discipline") 
print(syn[0].name())

type(syn[0].name())

"""> Care"""

syn = wordnet.synsets("care") 
syn

type(syn)

syn[0]

"""## Lemmas

Lemmas of code.v.02 (as in "convert ordinary language into code") are code.v.02.encipher, code.v.02.cipher, code.v.02.cypher, code.v.02.encrypt, code.v.02.inscribe, code.v.02.write_in_code
"""

print(syn[0].lemmas()[0].name())

"""## Definition"""

print(syn[0].definition())

print(syn[3].definition())

"""## Examples"""

print(syn[0].examples())

print(syn[1].examples())

print(syn[3].examples())

"""## Antonyms

> Synonyms of the word active are searched in the module synsets and are appended in the list synonyms. The same process is repeated for the Antonym also.
"""

synonyms = [] 
antonyms = [] 
for syn_set in wordnet.synsets("light"):  
  for l in syn_set.lemmas(): 
    synonyms.append(l.name()) 
    if l.antonyms(): 
      antonyms.append(l.antonyms()[0].name()) 
print("\nSet of synonyms of the word:", set(synonyms))
print("\nSet of antonyms of the word:", set(antonyms))

synonyms = [] 
antonyms = [] 
for syn_set in wordnet.synsets("light"):  
  #for l in syn_set.lemmas(): 
  synonyms.append(syn_set.name()) 
    #if l.antonyms(): 
       #antonyms.append(l.antonyms()[0].name()) 
print("\nSet of synonyms of the word:", set(synonyms))
print("\nSet of antonyms of the word:", set(antonyms))

"""# Main Code

> To find a word's synonym, part of speech, rank and definition.The words returned in range Minimum 10 Words-Maximum N Words.
"""

def Program_4():
  user_word = input("Enter the word: ")
  syn = wordnet.synsets(user_word) 

  word_list =[]
  pos_list = []
  rank_list = []
  defn_list = []

  pos_dict = {'n':'noun','v':'verb','a':'adjective','r':'adverb','s':'singular'}

  syn=list(syn)
  list1=[]
  for k in syn:
    list1.append(k)
    
  for i in range(len(list1)):
    value = str(list1[i])
    chunks = re.split("['.]",value)
    word_list.append(chunks[1])
    pos_list.append(pos_dict[chunks[2]])
    rank_list.append(chunks[3])
    defn_list.append(list1[i].definition())

  df = pd.DataFrame(list(zip(word_list, pos_list,rank_list,defn_list)),
                  columns =['Synonym Word', 'POS','Rank','Definition'])
  return df

Program_4()

"""# Similarity

#### 1.Thesaurus-based
"""

from nltk.corpus import wordnet as wn

dog = wn.synset('dog.n.01')
cat = wn.synset('cat.n.01')
hit = wn.synset('hit.v.01')
slap = wn.synset('slap.v.01')
discovery = wn.synset('discovery.n.01')
find = wn.synset('find.v.01')
care_n = wn.synset('care.n.01')
care_v = wn.synset('care.v.02')

"""- Path Similarity: 
> It is a similarity measure that finds the distance that is the length of the shortest path between two synsets. The score is in the range 0 to 1.
"""

print(dog.path_similarity(cat))

print(wn.path_similarity(hit, slap))

print(find.path_similarity(discovery))

print(find.path_similarity(find))

print(care_n.path_similarity(care_v))

syn1 = wordnet.synsets('football')
syn2 = wordnet.synsets('soccer')

# A word may have multiple synsets, so need to compare each synset of word1 with synset of word2
for s1 in syn1:
    for s2 in syn2:
        print("Path similarity of: ")
        print(s1, '(', s1.pos(), ')', '[', s1.definition(), ']')
        print(s2, '(', s2.pos(), ')', '[', s2.definition(), ']')
        print("   is", s1.path_similarity(s2))
        print()

"""Interpretation: The highest path similarity score of the words is 0.5, indicating they are closely related.

- Leacock-Chodorow (LCH) Similarity: 
> It is a similarity measure which is an extended version of Path-based similarity as it incorporates the depth of the taxonomy. Therefore, it is the negative log of the shortest path (spath) between two concepts (synset_1 and synset_2) divided by twice the total depth of the taxonomy (D). The LCH similarity scores are between 0 and 3.689
"""

print(dog.lch_similarity(cat))

print(wn.lch_similarity(hit, slap))

"""- Wu-Palmer (WUP) Similarity: 
> Return a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node). The score can be 0 < score <= 1. 
"""

print(dog.wup_similarity(cat))

print(wn.wup_similarity(hit, slap))

"""#### 2. Information Content metrics( Thesaurus and Corpus)

- Resnik (RES) Similarity: 
> Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node). It ranges from 0 for terms without similarity to infinity.
"""

# wordnet_ic Information Content: Load an information content file from the wordnet_ic corpus.
brown_ic = wordnet_ic.ic('ic-brown.dat')
semcor_ic = wordnet_ic.ic('ic-semcor.dat')
# Or you can create an information content dictionary from a corpus 
genesis_ic = wn.ic(genesis, False, 0.0)

print(dog.res_similarity(cat, brown_ic))

print(dog.res_similarity(cat, genesis_ic))

"""- Jiang-Conrath (JCN) Similarity: 
> Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node) and that of the two input Synsets.

Equation: 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).
"""

print(dog.jcn_similarity(cat, brown_ic))

print(dog.jcn_similarity(cat, genesis_ic))

"""- Lin Similarity: 
> Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node) and that of the two input Synsets.

Equation: 2 * IC(lcs) / (IC(s1) + IC(s2)).
"""

print(dog.lin_similarity(cat, brown_ic))

print(dog.lin_similarity(cat, genesis_ic))

"""## Additional to Similarity

If you also want the "similar to" list, that's not the same thing as the synonyms. For that, you call similar_tos() on each Synset.
"""

for s in wn.synsets('small'):
    print(s)
    for sim in s.similar_tos():
        print('  ->  {}'.format(sim))